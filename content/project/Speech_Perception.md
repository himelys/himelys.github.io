+++
# Date this page was created.
date = "2018-02-25"

# Project title.
title = "Object-based Speech Perception"

# Project summary to display on homepage.
summary = ""

# Optional image to display on homepage (relative to `static/img/` folder).
image_preview = "white_noise_contour.png"

# Tags: can be used for filtering projects.
# Example: `tags = ["machine-learning", "deep-learning"]`
tags = ["signal-processing", "speech-perception"]

# Optional external URL for project (replaces project detail page).
external_link = ""

# Does the project detail page use math formatting?
math = false

# Optional featured image (relative to `static/img/` folder).
[header]
image = "human_speech_ex.png"
caption = ""

+++

In this project, we analyze various kinds of sound signals including human speech, animal vocalizations and even noise to understand the human auditory perception using time-frequency analysis and neural responses (mostly EEG). Currently, we are trying to develop a python-based time-frequency analysis toolbox and design an auditory psychophysics experiment to test whether or not stable time-frequency structures are important for signal detection and speech perception.


For more information, refer to [this github page!](https://github.com/himelys/Sparse_Contour_TF)
